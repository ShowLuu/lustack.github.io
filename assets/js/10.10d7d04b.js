(window.webpackJsonp=window.webpackJsonp||[]).push([[10],{310:function(s,a,t){s.exports=t.p+"assets/img/6.b49f9985.png"},335:function(s,a,t){"use strict";t.r(a);var e=t(14),r=Object(e.a)({},(function(){var s=this,a=s._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("h1",{attrs:{id:"一、基本概念"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#一、基本概念"}},[s._v("#")]),s._v(" 一、基本概念")]),s._v(" "),a("p",[s._v("AR=ISR+OSR")]),s._v(" "),a("p",[s._v("AR，所有副本")]),s._v(" "),a("p",[s._v("ISR，与leader保持一定的同步速度的副本")]),s._v(" "),a("p",[s._v("OSR，与leader同步停滞过多的副本")]),s._v(" "),a("p",[s._v("HW，消费者下一次拉取消息的最大offset")]),s._v(" "),a("p",[s._v("LEO(Log End Offset)，消息写入日志的下一次的位置")]),s._v(" "),a("p",[s._v("LSO(LastStableOffset)，生产者提交事务的最后位置。isolation.level，read_uncommitted读到未提交的，此时lso=hw；read_committed读生产者已经提交的")]),s._v(" "),a("p",[s._v("LSO≤HW≤LEO")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[s._v("后台启动，并将pid记录日志\n"),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("nohup")]),s._v(" ./bin/kafka-server-start.sh config/server.properties "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("echo")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$!")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" pid.txt\n\n杀死服务\n"),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("kill")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("-9")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token variable"}},[a("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("cat")]),s._v(" pid.txt"),a("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br")])]),a("h1",{attrs:{id:"二、常见命令"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#二、常见命令"}},[s._v("#")]),s._v(" 二、常见命令")]),s._v(" "),a("h2",{attrs:{id:"一-与主题有关的kafka-topic-sh脚本"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#一-与主题有关的kafka-topic-sh脚本"}},[s._v("#")]),s._v(" (一)与主题有关的Kafka-topic.sh脚本")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[s._v("查看主题\n./bin/kafka-topics.sh "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--zookeeper")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("127.0")]),s._v(".0.1:2181 "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--list")]),s._v("\n\n创建主题"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("自动分配分区副本"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nbin/kafka-topics.sh "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--zookeeper")]),s._v(" localhost:2181/kafka "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--create")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--topic")]),s._v(" topic-demo --replication-factor "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--partitions")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v("\n\n创建主题"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("自定义分配分区副本"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n./bin/kafka-topics.sh "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--zookeeper")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("127.0")]),s._v(".0.1:2181 "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--create")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--topic")]),s._v(" lu-learn --replica-assignment "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(":1:2,1:2:0,2:0:1\n\n创建主题"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("带上配置"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n./bin/kafka-topics.sh "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--zookeeper")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("127.0")]),s._v(".0.1:2181 "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--create")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--topic")]),s._v(" lu-learn --replica-assignment "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(":1:2,1:2:0,2:0:1 "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--config")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("max.message.bytes")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("10000")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--config")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("cleanup.policy")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("compact\n\n展示主题分区副本信息\nbin/kafka-topics.sh "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--zookeeper")]),s._v(" localhost:2181/kafka "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--describe")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--topic")]),s._v(" topic-demo\n\n找出使用了config额外配置的主题\n./bin/kafka-topics.sh "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--zookeeper")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("127.0")]),s._v(".0.1:2181 "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--describe")]),s._v(" --topics-with-overrides\n\n找出所有包含失效副本的分区"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("ISR"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v("AR，即OSR存在分区"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n./bin/kafka-topics.sh "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--zookeeper")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("127.0")]),s._v(".0.1:2181 "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--describe")]),s._v(" --under-replicated-partitions\n\n找出问题的分区\n./bin/kafka-topics.sh "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--zookeeper")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("127.0")]),s._v(".0.1:2181 "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--describe")]),s._v(" --unavailable-partitions\n\n删除主题\nbin/kafka-topics.sh "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--zookeeper")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("127.0")]),s._v(".0.1:2181 "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--delete")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--topic")]),s._v(" lu-learn\n\n修改主题"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("修改分区数，只能增不能减"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n./bin/kafka-topics.sh "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--zookeeper")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("127.0")]),s._v(".0.1:2181 "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--alter")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--topic")]),s._v(" lu-learn "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--partitions")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v("\n\n修改主题配置\n./bin/kafka-topics.sh "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--zookeeper")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("127.0")]),s._v(".0.1:2181 "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--alter")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--topic")]),s._v(" lu-learn "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--config")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("segment.bytes")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1048577")]),s._v("\n\n删除主题配置\n/bin/kafka-topics.sh "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--zookeeper")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("127.0")]),s._v(".0.1:2181 "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--alter")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--topic")]),s._v(" lu-learn --delete-config segment.bytes\n\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br"),a("span",{staticClass:"line-number"},[s._v("22")]),a("br"),a("span",{staticClass:"line-number"},[s._v("23")]),a("br"),a("span",{staticClass:"line-number"},[s._v("24")]),a("br"),a("span",{staticClass:"line-number"},[s._v("25")]),a("br"),a("span",{staticClass:"line-number"},[s._v("26")]),a("br"),a("span",{staticClass:"line-number"},[s._v("27")]),a("br"),a("span",{staticClass:"line-number"},[s._v("28")]),a("br"),a("span",{staticClass:"line-number"},[s._v("29")]),a("br"),a("span",{staticClass:"line-number"},[s._v("30")]),a("br"),a("span",{staticClass:"line-number"},[s._v("31")]),a("br"),a("span",{staticClass:"line-number"},[s._v("32")]),a("br"),a("span",{staticClass:"line-number"},[s._v("33")]),a("br"),a("span",{staticClass:"line-number"},[s._v("34")]),a("br"),a("span",{staticClass:"line-number"},[s._v("35")]),a("br"),a("span",{staticClass:"line-number"},[s._v("36")]),a("br")])]),a("h2",{attrs:{id:"二-生产消费相关脚本kafka-console-producer-sh-和-kafka-console­-consumer-sh"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#二-生产消费相关脚本kafka-console-producer-sh-和-kafka-console­-consumer-sh"}},[s._v("#")]),s._v(" (二)生产消费相关脚本kafka-console-producer.sh 和 kafka-console­ consumer. sh")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[s._v("消费者订阅主题\nbin/kafka.console-consumer.sh --bootstrap-server localhost:9092 "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--topic")]),s._v(" topic-demo\n\n生产者生产消息\nbin/kafka.console-producer.sh --broker-list losthost:9092 "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--topic")]),s._v(" topic-demo\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br")])]),a("h2",{attrs:{id:"三-与配置有关的脚本kafka-configs-sh"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#三-与配置有关的脚本kafka-configs-sh"}},[s._v("#")]),s._v(" (三)与配置有关的脚本kafka-configs.sh")]),s._v(" "),a("ul",[a("li",[a("p",[s._v("支持两类：变更配置alter、查看配置describe")])]),s._v(" "),a("li",[a("p",[s._v("查看配置describe")]),s._v(" "),a("ul",[a("li",[s._v("模版：bin/kafka-configs.sh --zookeeper 127.0.0.1:2181 --describe --entity-type xxx entity-name xxx\n"),a("ul",[a("li",[s._v("entity-type：topics、brokers、clients、users")]),s._v(" "),a("li",[a("img",{attrs:{src:t(310),alt:"image-20201108171043478"}})])])])])]),s._v(" "),a("li",[a("p",[s._v("变更配置alter")]),s._v(" "),a("ul",[a("li",[s._v("add-config：增改")]),s._v(" "),a("li",[s._v("delete-config：删")])])])]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[s._v("./bin/kafka-configs.sh "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--zookeeper")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("127.0")]),s._v(".0.1:2181 \n\n./bin/kafka-configs.sh "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--zookeeper")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("127.0")]),s._v(".0.1:2181 "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--alter")]),s._v(" --entity-type topics --entity-name lu-learn --add-config "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("max.message.bytes")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("10001")]),s._v(" \n\n./bin/kafka-configs.sh "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--zookeeper")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("127.0")]),s._v(".0.1:2181 "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--alter")]),s._v(" --entity-type topics --entity-name lu-learn --delete-config max.message.bytes\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br")])]),a("h2",{attrs:{id:"四-对leader副本进行重平衡的功能kafka-preferred-replics-election-sh"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#四-对leader副本进行重平衡的功能kafka-preferred-replics-election-sh"}},[s._v("#")]),s._v(" (四)对leader副本进行重平衡的功能kafka-preferred-replics-election.sh")]),s._v(" "),a("ul",[a("li",[a("p",[s._v("再平衡，就是通过zk重新选举，把当前分区的优先副本选举为leader副本.")]),s._v(" "),a("ul",[a("li",[s._v("可以配置broker的再平衡策略，例如是否需要开启再平衡机制，开启再平衡机制，多久检测一次？因为再平衡操作，主要是为了让整个集群负载均衡，且再平衡时，为了保证安全性，所有其他等操作都会暂时停止，对于高并发吞吐的场景，可能会造成丢消息等情况，例如再平衡出发，手动提交偏移量没有执行提交。所以这个策略是情况而定，一般建议手动执行脚本出发。集群负载不均衡也是可用，不用一味的发现需要再平衡的情况就立马执行再平衡，通常也需要一个阈值判断。也需要考虑每个服务器的硬件环境。")])])]),s._v(" "),a("li",[a("p",[s._v("对所有主题分区进行重平衡：./bin/kafka-preferred-replica-election.sh --zookeeper localhost:2181")])]),s._v(" "),a("li",[a("p",[s._v("指定主题分区进行重平衡：./bin/kafka-preferred-replica-election.sh --zookeeper localhost:2181 --path-to-json-file preferred-replica-election-json.txt")]),s._v(" "),a("div",{staticClass:"language-json line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-json"}},[a("code",[s._v("preferred-replica-election-json.txt文件内容\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"partitions"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n       "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n           "),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"partition"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n           "),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"topic"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"lu-learn"')]),s._v("\n       "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n       "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n           "),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"partition"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n           "),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"topic"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"lu-learn"')]),s._v("\n       "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n           "),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"partition"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n           "),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"topic"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"lu-learn"')]),s._v("\n       "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n   "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" \n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br")])])])]),s._v(" "),a("h2",{attrs:{id:"五-分区重分配kafka-reassign-partitions-sh"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#五-分区重分配kafka-reassign-partitions-sh"}},[s._v("#")]),s._v(" (五)分区重分配kafka-reassign-partitions.sh")]),s._v(" "),a("ul",[a("li",[a("p",[s._v("原理")]),s._v(" "),a("ul",[a("li",[s._v("数据复制：现增加新的副本，然后进行数据同步，最后删除旧的副本。")])])]),s._v(" "),a("li",[a("p",[s._v("应用场景：")]),s._v(" "),a("ul",[a("li",[s._v("当需要对集群中的某一个节点下线时，为了保证分区及副本的合理分配，可以通过此脚本将该节点上的分区副本迁移到其他的可用节点上。")]),s._v(" "),a("li",[s._v("当集群中新增broker节点时，只有新创建的主题分区才有肯呢个分配到那个新增的节点上，而之前的主题分区则不会自动分配加入到新的节点上，此时就需要分区的冲分配机制了。")])])]),s._v(" "),a("li",[a("p",[s._v("步骤：")]),s._v(" "),a("ul",[a("li",[a("p",[s._v("创建一个json文件")]),s._v(" "),a("div",{staticClass:"language-json line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-json"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"topics"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"topic"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"lu-test"')]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"version"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br")])])]),s._v(" "),a("li",[a("p",[s._v("根据该json指定所要分配的broker节点列表来生成一份重分配的方案")]),s._v(" "),a("ul",[a("li",[a("p",[s._v("执行命令：./bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 --generate --topics-to-move-json-file reassign-partitions-json.txt --broker-list 0,2")])]),s._v(" "),a("li",[a("p",[s._v("得到服务器端返回json")]),s._v(" "),a("div",{staticClass:"language-json line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-json"}},[a("code",[s._v("Current partition replica assignment\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"version"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"partitions"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"topic"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"lu-test"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"partition"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"replicas"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"log_dirs"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"any"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"any"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"topic"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"lu-test"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"partition"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"replicas"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"log_dirs"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"any"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"any"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"topic"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"lu-test"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"partition"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"replicas"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"log_dirs"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"any"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"any"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"topic"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"lu-test"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"partition"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"replicas"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"log_dirs"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"any"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"any"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\nProposed partition reassignment configuration\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"version"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"partitions"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"topic"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"lu-test"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"partition"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"replicas"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"log_dirs"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"any"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"any"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"topic"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"lu-test"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"partition"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"replicas"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"log_dirs"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"any"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"any"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"topic"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"lu-test"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"partition"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"replicas"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"log_dirs"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"any"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"any"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"topic"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"lu-test"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"partition"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"replicas"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token property"}},[s._v('"log_dirs"')]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"any"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"any"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br")])])])])]),s._v(" "),a("li",[a("p",[s._v("将上面第二个json保存为文件，执行命令")]),s._v(" "),a("ul",[a("li",[s._v("执行命令：./bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 --execute --reassignment-json-file reassign-partitions-json-execute.txt")]),s._v(" "),a("li",[s._v("验证命令：./bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 --verify --reassignment-json-file reassign-partitions-json-execute.txt")])])])])]),s._v(" "),a("li",[a("p",[s._v("分区重分配限流")]),s._v(" "),a("ul",[a("li",[s._v("前几个步骤和上面一样")]),s._v(" "),a("li",[s._v("执行命令不同，实际上就多加了一个参数配置：throttle。执行完毕，自动清除设置"),a("code",[s._v("Throttle was removed.")]),s._v(" "),a("ul",[a("li",[s._v("./bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 --execute --reassignment-json-file reassign-partitions-json-execute.txt --throttle 1024")])])])])])]),s._v(" "),a("h2",{attrs:{id:"六-压测脚本kafka-producer-perf-test-sh、kafka-consumer-perf-test-sh"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#六-压测脚本kafka-producer-perf-test-sh、kafka-consumer-perf-test-sh"}},[s._v("#")]),s._v(" (六)压测脚本kafka-producer-perf-test.sh、kafka-consumer-perf-test.sh")]),s._v(" "),a("ul",[a("li",[a("p",[s._v("生产者压测脚本kafka-consumer-perf-test.sh")]),s._v(" "),a("ul",[a("li",[a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[s._v("执行：./bin/kafka-producer-perf-test.sh "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--topic")]),s._v(" lu-learn --num-records "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("100000")]),s._v(" --record-size "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1024")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--throughput")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("-1")]),s._v(" --producer-props "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("bootstrap.servers")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("localhost:9092 "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("acks")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n\n响应：10000 records sent, "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("15649.452269")]),s._v(" records/sec "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("15.28")]),s._v(" MB/sec"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("205.12")]),s._v(" ms avg latency, "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("321.00")]),s._v(" ms max latency, "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("218")]),s._v(" ms 50th, "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("310")]),s._v(" ms 95th, "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("317")]),s._v(" ms 99th, "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("318")]),s._v(" ms "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("99")]),s._v(".9th.\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br")])])]),s._v(" "),a("li",[a("p",[s._v("请求参数：")]),s._v(" "),a("ul",[a("li",[s._v("num-records：指定发送消息总数")]),s._v(" "),a("li",[s._v("record-size：设置每条消息的字节数")]),s._v(" "),a("li",[s._v("producer-props：指定生产者客户端的配置")]),s._v(" "),a("li",[s._v("producer.config：指定生产者服务端的配置")]),s._v(" "),a("li",[s._v("throughput：吞吐量限流控制"),a("code",[s._v("<0")]),s._v("不限流")]),s._v(" "),a("li",[s._v("print-mertrics：打印显示更多的指标")])])]),s._v(" "),a("li",[a("p",[s._v("响应参数：")]),s._v(" "),a("ul",[a("li",[s._v("records sent：发送消息总数")]),s._v(" "),a("li",[s._v("records/sec：以每秒发送的消息数来统计吞吐量，括号里面的MB/sec表示以每秒发送消息大小来统计吞吐量")]),s._v(" "),a("li",[s._v("avg latency：消息处理的平均耗时")]),s._v(" "),a("li",[s._v("max latency：消息处理额最大耗时")]),s._v(" "),a("li",[s._v("218 ms 50th, 310 ms 95th, 317 ms 99th, 318 ms 99.9th：表示50%、95%、99%、99.9%的消息处理耗时")])])])])]),s._v(" "),a("li",[a("p",[s._v("消费者压测脚本kafka-consumer-perf-test.sh")]),s._v(" "),a("ul",[a("li",[a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[s._v("执行：./bin/kafka-consumer-perf-test.sh "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--topic")]),s._v(" lu-learn "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--messages")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1000")]),s._v(" --broker-list localhost:9092\n\n响应：start.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec\n"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2020")]),s._v("-11-15 "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("23")]),s._v(":14:05:208, "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2020")]),s._v("-11-15 "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("23")]),s._v(":14:05:389, "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.9766")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5.3954")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1000")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5524.8619")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("12")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("169")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5.7785")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5917.1598")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br")])])]),s._v(" "),a("li",[a("p",[s._v("响应参数")]),s._v(" "),a("ul",[a("li",[s._v("start.time、end.time：起止运行时间")]),s._v(" "),a("li",[s._v("data.consumed.in.MB：消费消息的总量，单位MB")]),s._v(" "),a("li",[s._v("MB.sec：按字节大小计算的消费吞吐量，单位MB/s")]),s._v(" "),a("li",[s._v("data.consumed.in.nMsg：消费的消息总数")]),s._v(" "),a("li",[s._v("nMsg.sec：按个数计算的吞吐量")]),s._v(" "),a("li",[s._v("rebalance.time.ms：再平衡时间，单位ms")]),s._v(" "),a("li",[s._v("fetch.time.ms：拉取消息的持续时间，单位ms\n"),a("ul",[a("li",[s._v("fetch.time.ms = end.time - start.time - rebalance.time.ms")])])]),s._v(" "),a("li",[s._v("fetch.MB.sec：每秒拉取消息的字节大小，单位MB/s")]),s._v(" "),a("li",[s._v("fetch.nMsg.sec：每秒拉取消息的个数")])])])])])]),s._v(" "),a("h2",{attrs:{id:"七-kafka-run-class-sh"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#七-kafka-run-class-sh"}},[s._v("#")]),s._v(" (七)kafka-run-class.sh")]),s._v(" "),a("ul",[a("li",[a("p",[s._v("日志")]),s._v(" "),a("ul",[a("li",[a("p",[s._v("查看")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[s._v("./bin/kafka-run-class.sh kafka.tools.DumpLogSegments "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--files")]),s._v(" /Users/zhanglu/Desktop/lu/tool/dev/kafka/kafka_colony/kafka_2.11-2.2.0_0/logs/lu-learn-0/00000000000000008464.log \n\nV0版本，一条MsgSize "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" 12B"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("日志消息头部"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("+14B"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("日志消体最小"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("+KeySize+ValueSize\nV1版本，一条MsgSize "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" 12B"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("日志消息头部"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("+22B"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("日志消体最小"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("+KeySize+ValueSize\nV2版本，变长字段Varints，更加节省空间，还支持更多额功能，事务、幂等性\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br")])])]),s._v(" "),a("li",[a("p",[s._v("1")])])])])]),s._v(" "),a("h2",{attrs:{id:"八"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#八"}},[s._v("#")]),s._v(" (八)")]),s._v(" "),a("ul",[a("li",[s._v("./bin/kafka-dump-log.sh --files /Users/zhanglu/Desktop/lu/tool/dev/kafka/kafka_colony/kafka_2.11-2.2.0_0/logs/lu-learn-0/00000000000000008465.index")])]),s._v(" "),a("h1",{attrs:{id:"三、参数配置"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#三、参数配置"}},[s._v("#")]),s._v(" 三、参数配置")]),s._v(" "),a("h2",{attrs:{id:"一-服务端参数配置"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#一-服务端参数配置"}},[s._v("#")]),s._v(" (一)服务端参数配置")]),s._v(" "),a("ul",[a("li",[s._v("zookeeper.connect：指明broker要连接的zk集群地址，可以127.0.0.1:2181/kafka")]),s._v(" "),a("li",[s._v("listeners\n"),a("ul",[a("li",[s._v("指明broker监听客户端连接的地址列表，多个地址逗号隔开，protocoll://hostname:port，协议类型PLAINTEXT、SSL、SASL")]),s._v(" "),a("li",[s._v("不填，有可能会绑定到127.0.0.1这样无法对外提供服务，如果主机名是0.0.0.0，则表示绑定到所有的网卡")]),s._v(" "),a("li",[s._v("绑定私网IP供broker间通信")])])]),s._v(" "),a("li",[s._v("advertised.listeners：绑定公网IP供外部客户端使用。")]),s._v(" "),a("li",[s._v("broker.id：kafka集群中的标识。")]),s._v(" "),a("li",[s._v("log.dir、log.dirs：配置消息以日志文件的形式持久化到磁盘，配置路径。")]),s._v(" "),a("li",[s._v("enable.topic.delete：默认值true。可以删除主题。")]),s._v(" "),a("li",[s._v("auto.create.topics.enable：根据消息自动创建主题，默认值true。")]),s._v(" "),a("li",[s._v("auto.leader.rebalance.enable：分区自动平衡，默认值true。控制器会启动一个定时任务，轮询所有的broker节点计算每个节点的分区不平衡率(不平衡率=非优先副本的leader个数/分区总数)，是否超过leader.imbalance.per.broker.percentage参数的配置比值，默认值10%，若超过该值则会自动执行优先副本选举，执行周期由参数leader.imbalance.check.interval.seconds控制，默认值300s。")]),s._v(" "),a("li",[s._v("leader.imbalance.check.interval.seconds：默认值300s。定时周期检查leader是否分布不均衡。")]),s._v(" "),a("li",[s._v("max.message.bytes："),a("code",[s._v("max.message.bytes")]),s._v("指定broker所能接收消息的最大值，默认值1000012B，约976.6KB")]),s._v(" "),a("li",[s._v("replica.lag.time.max.ms：follower副本滞后的时间。只要follower每隔一段时间都可以发送FetchRequest给Leader，那个该副本不会被标记为Dead从而从ISR中移入OSR中。")]),s._v(" "),a("li",[s._v("compression.type：消息压缩类型producer、uncompressed、snappy、lz4、gzip。默认值producer，表示生产者中所使用的原始压缩类型。")]),s._v(" "),a("li",[s._v("leader.replication.throttled.replicas：用来配置被限制速率的主题所对应的leader副本列表。")]),s._v(" "),a("li",[s._v("follower.replication.throttled.replicas：用来配置被限制速率的主题所对应的follower副本列表。")]),s._v(" "),a("li",[s._v("min.insync.replicas：分区ISR集合中至少要有多少个副本。默认值1。")]),s._v(" "),a("li",[s._v("unclean.leader.election.enable：是否可以从非ISR集合中选举leader副本，默认值false，若true则可能造成数据丢失。")]),s._v(" "),a("li",[s._v("log.cleanup.policy："),a("code",[s._v("cleanup.policy")]),s._v("日志压缩策略delete、compact。默认delete。")]),s._v(" "),a("li",[s._v("log.cleaner.delete.retention.ms："),a("code",[s._v("delete.retention.ms")]),s._v("被标识为删除的数据能够保留多久。默认值1天。")]),s._v(" "),a("li",[s._v("log.segment.delete.delay.ms："),a("code",[s._v("file.delete.delay.ms")]),s._v("清理文件之前可以等待多长时间。默认值1分钟。")]),s._v(" "),a("li",[s._v("log.flush.interval.message："),a("code",[s._v("flush.message")]),s._v("需要收集多少消息才会将它们强制刷新到磁盘，默认值Long.MAX_VALUE，即让操作系统来决定。")]),s._v(" "),a("li",[s._v("log.flush.interval.ms："),a("code",[s._v("flush.ms")]),s._v("需要等待多久才会将消息刷新到磁盘，默认值Long.MAX_VALUE，即让操作系统来决定。")]),s._v(" "),a("li",[s._v("log.index.interval.bytes："),a("code",[s._v("index.interval.bytes")]),s._v("用来控制添加索引项的频率。每超过这个参数设置的消息字节数时就可以添加一个新的索引项，默认值为4096。")]),s._v(" "),a("li",[s._v("log.message.format.version："),a("code",[s._v("message.format.version")]),s._v("消息格式的版本。")]),s._v(" "),a("li",[s._v("log.message.timestamp.difference.max.ms："),a("code",[s._v("message.timestamp.difference.max.ms")]),s._v("消息中自带的时间戳与broker收到消息的时间戳之间最大的差值，默认值为Long.MAX_VALUE。当log.messgae.timestamp.type=CreateTime时有效")]),s._v(" "),a("li",[s._v("log.messgae.timestamp.type："),a("code",[s._v("message.timestamp.type")]),s._v("消息的时间戳类型。默认值CreateTime。logAppendTime。")]),s._v(" "),a("li",[s._v("log.cleaner.min.cleanable.ratio："),a("code",[s._v("min.cleanable.dirty.ratio")]),s._v("日志清理时的最小污浊率。默认值0.5。")]),s._v(" "),a("li",[s._v("log.cleaner.min.compaction.lag.ms："),a("code",[s._v("min.compaction.lag.ms")]),s._v("日志在被清理前的最小保留时间，默认值0。")]),s._v(" "),a("li",[s._v("log.preallocate："),a("code",[s._v("preallocate")]),s._v("在创建日志分段的时候是否要预分配空间，默认值false。")]),s._v(" "),a("li",[s._v("log.retention.bytes："),a("code",[s._v("retention.bytes")]),s._v("分区中所能保留的消息总量，默认值-1，没有限制。")]),s._v(" "),a("li",[s._v("log.retention.ms："),a("code",[s._v("retention.ms")]),s._v("使用delete的日志清理策略时，消息能够保留的多长时间，默认值7天。若设置-1，没有期限。")]),s._v(" "),a("li",[s._v("log.segment.bytes："),a("code",[s._v("segment.bytes")]),s._v("日志分段的最大值。默认值1GB。")]),s._v(" "),a("li",[s._v("log.index.sizemax.bytes："),a("code",[s._v("segment.index.bytes")]),s._v("日志分段索引的最大值。默认值10MB。")]),s._v(" "),a("li",[s._v("log.roll.jitter.ms："),a("code",[s._v("segment.jitter.ms")]),s._v("滚动日志分段时，在segment.ms的基础之上增加的随机数，默认值0。")]),s._v(" "),a("li",[s._v("log.roll.ms："),a("code",[s._v("segment.ms")]),s._v("最长对酒滚动一次日志分段，默认值7天。")]),s._v(" "),a("li",[s._v("follower.replication.throttled.rate：设置副本的复制的速度。单位B/s。")]),s._v(" "),a("li",[s._v("leader.replication.throttled.rate：设置leader副本传输的速度。单位B/s。")])]),s._v(" "),a("h2",{attrs:{id:"二-、客户端参数配置"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#二-、客户端参数配置"}},[s._v("#")]),s._v(" (二)、客户端参数配置")]),s._v(" "),a("h3",{attrs:{id:"_1-生产者参数配置"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-生产者参数配置"}},[s._v("#")]),s._v(" 1.生产者参数配置")]),s._v(" "),a("ul",[a("li",[s._v("bootstrap.servers")]),s._v(" "),a("li",[s._v("key. serializer、value.serializer：broker端接收的消息必须以字节(byte[])的形式存在")]),s._v(" "),a("li",[s._v("client.id：生产者客户端id")]),s._v(" "),a("li",[s._v("buffer.memory：默认值为32MB。RecordAccumulator缓存的大小。生产者客户端缓存消息的缓冲区大小。")]),s._v(" "),a("li",[s._v("max.block.ms：默认值60000。由于RecordAccumulator缓存的大小不足，send()客户端发送数据到broker时需要阻塞等待，超时则抛出异常")]),s._v(" "),a("li",[s._v("batch.size：默认值16KB。byteBuffer复用的缓存，不会频繁对内存的创建和释放，实现缓存的高效利用。当一个ProducerRecord流入RecordAccumulator时，根据分区找到对应的双端队列，若ProducerBatch空则新建，若ProducerBatch内存还够则可以写入，反之新建，新建ProducerBatch时会判断该ProducerRecord的大小是否超过batch.size，若没超过则按照batch.size创建，反之，则以ProducerBatch大小来创建。以batch.size创建的内存快，可以通过BufferPool的管理来进行复用。")]),s._v(" "),a("li",[s._v("消息发送数据结构过程：\n"),a("ul",[a("li",[a("code",[s._v("<分区，Deque<ProducerBatch>>")]),s._v("：ProducerRecord->RecordAccumulator")]),s._v(" "),a("li",[a("code",[s._v("<Node，List<ProducerBatch>>")]),s._v("：Sender从RecordAccumulator中获取缓存的消息")]),s._v(" "),a("li",[a("code",[s._v("<Node，Request>")]),s._v("：转换成该格式，Sender线程发送至broker")]),s._v(" "),a("li",[a("code",[s._v("Map<NodeId，Deque<Request>>")]),s._v("：Sender线程发送至broker前，将请求封装成该格式(InFlightRequests)。作用，缓存已经发出去但还没有收到响应的请求")])])]),s._v(" "),a("li",[s._v("max.in.flight.requests.per.connection：默认值5。每个连接最多只能缓存5个未响应的请求。由于重试机制，可能无法保证消息在分区内的顺序性。例如：消息A、消息B，ack != 0，max.in.flight.requests.per.connection大于1，A发完B发，A的时候由于网络抖动发送失败了，触发重试机制，B继续发送且成功了，A重试之后发送成功，BA，消息在分区内的顺序性没有得到保障。当ack等于0，无法知晓消息成功与否，不会触发重试机制。一般建议把max.in.flight.requests.per.connection设置为1，而不是把ack配置为0。max.in.flight.requests.per.connection设置为1，只有A重试成功才会继续执行B。")]),s._v(" "),a("li",[s._v("leastLoaderNode：负载最小的节点。InFlightRequests数量越少，说明请求响应速度越快，负载越小。用于做元数据请求，消费者组播协议的交互。")]),s._v(" "),a("li",[s._v("asks：\n"),a("ul",[a("li",[s._v("1：默认值，只保证leader副本成功。一开始leader成功之后返回，当follower同步leader前，leader挂了，follower拉取不到leader最新的数据，就开始选举leader，数据丢失。")]),s._v(" "),a("li",[s._v("0：不等待。消息写入kafka过程中出现异常。")]),s._v(" "),a("li",[s._v("-1/all：等待ISR中所有副本都成功写入消息。当ISR中只有一个副本时，当leader挂了，OSR追上之后重新选举为leader后，消息丢失。")])])]),s._v(" "),a("li",[s._v("max.request.size：生产者客户端能发送消息的最大值。默认值1MB。")]),s._v(" "),a("li",[s._v("retries：生产者重试的次数。默认值0。网络抖动、leader选举等，这些异常是可以重试。像消息太大，超过max.reqyest.size，就不会触发重试机制。")]),s._v(" "),a("li",[s._v("retry.backoff.ms：默认值100。设定两次重试之间的时间间隔。需要预测异常恢复的时间，以便更精准的控制重试机制，避免过早的放弃重试。")]),s._v(" "),a("li",[s._v('compression.type：消息压缩方式，默认值"none"。'),a("code",[s._v("gzip、snappy、lz4")]),s._v("。时间换空间。")]),s._v(" "),a("li",[s._v("connections.max.idle.ms：多久之后关闭限制的连接，默认值9分钟。")]),s._v(" "),a("li",[s._v("linger.ms：生产者发送ProducerBatch之前等待更多的消息。默认为0。增大该参数值会增加消息写入的延迟，但可以提升一定的吞吐量。")]),s._v(" "),a("li",[s._v("receive.buffer.bytes：设置Socket接收消息缓冲区的大小。默认值32KB。-1则使用操作系统的默认值。如果Producer与Kafka处于不同机房，可适当调大该参数。")]),s._v(" "),a("li",[s._v("send.buffer.bytes：设置Socket发送消息缓冲区的大小。默认值128KB。-1则使用操作系统默认值。")]),s._v(" "),a("li",[s._v("request.timeout.ms：配置Producer等待请求响应的最长时间，默认值30000ms。不管ack怎么配置，请求服务端之后，等待响应的时间也有个限制。要保证request.timeout.ms大于broker配置的replica.lag.time.max.ms，以防止消息重复提交至服务端的副本上(follower还在同步Leader数据，客户端因为请求超时)。")]),s._v(" "),a("li",[s._v("partitioner.class：分区器。")]),s._v(" "),a("li",[s._v("interceptor.class：拦截器。")]),s._v(" "),a("li",[s._v("enable.idempotence：默认值false。幂等性。")]),s._v(" "),a("li",[s._v("metadata.max.age.ms：默认值5分钟。元数据更新的最长时间间隔，时间段内，元数据没更新则强制更新。")]),s._v(" "),a("li",[s._v("transactional.id：默认值null。设置事务id，必须唯一。")])]),s._v(" "),a("h3",{attrs:{id:"_3-消费者参数配置"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-消费者参数配置"}},[s._v("#")]),s._v(" 3.消费者参数配置")]),s._v(" "),a("ul",[a("li",[s._v("bootstrap.servers")]),s._v(" "),a("li",[s._v('group.id：配置消费组，默认值""。')]),s._v(" "),a("li",[s._v("key.deserializer、value.deserializer：kv反序列化器")]),s._v(" "),a("li",[s._v("client.id：消费者客户端id")]),s._v(" "),a("li",[s._v("enable.auto.commit：默认值true。自动提交，根据auto.commit.interval.ms周期提交。自动提交的操作在poll方法里面实现。\n"),a("ul",[a("li",[s._v("重复消费情况：消息处理完毕，在提交前消费者挂了，则本次消费位移没有提交，恢复后会重新读这批消息。")]),s._v(" "),a("li",[s._v("消息丢失情况：消息正在处理，还未处理完成前，本次消费位移已经提交，消息处理的挂了(此时业务还没有处理完成)，恢复后不会重新读这批消息。")]),s._v(" "),a("li",[s._v("手动提交依然会产生重复消费的情况：\n"),a("ul",[a("li",[s._v("消费处理逻辑完了，手动提交时，kafka挂了，偏移量没有更新到kafka上，kafka恢复，重复消费")]),s._v(" "),a("li",[s._v("由于新增分区、组内消费者数量变动，触发再平衡时。再平衡期间，消费组变得不可用，若还未来得及提交偏移量就触发再平衡了，当分区重新绑定消费者时，会重复消费。")])])]),s._v(" "),a("li",[s._v("避免重复消费的解决方案：\n"),a("ul",[a("li",[s._v("手动提交")]),s._v(" "),a("li",[s._v("每处理完一次业务，就把偏移量存入redis，再平衡后(消费者线程开始重新工作前)，监听器的回调方法里面将redis的偏移量设置kafka主题分区，从redis项目关闭前确保先停止消费者线程并把消费位移更新到redis上，项目重启，消费者线程工作前，读取redis偏移量设置kafka主题分区。")])])])])]),s._v(" "),a("li",[s._v("auto.commit.interval.ms：默认值5s，自动提交间隔。")]),s._v(" "),a("li",[s._v('auto.offset.reset：默认值"latest"。当找不到当前的消费位移或者位移越界时，默认从分区末尾开始消费。“earliest”从头开始消费。"none"不消费，抛异常。')]),s._v(" "),a("li",[s._v("fetch.min.bytes：配置consumer客户端poll()能从kafka中拉取的最小数据量。默认值1B。")]),s._v(" "),a("li",[s._v("fetch.max.bytes：配置consumer客户端poll()能从kafka中拉取的最大数据量。默认值50MB。若一条消息大小10B，该值1B，仍然可以正常拉取到消费。")]),s._v(" "),a("li",[s._v("fetch.max.wait.ms：poll等待时间。默认值500ms。")]),s._v(" "),a("li",[s._v("max.partition.fetch.bytes：配置从每个分区里返回给consumer的最大数据量。默认值1M。")]),s._v(" "),a("li",[s._v("max.poll.records：一次poll，最大的消息数量。默认值500条。")]),s._v(" "),a("li",[s._v("connections.max.idle.ms：指定在多久之后关闭限制的连接，默认值9分钟。")]),s._v(" "),a("li",[s._v("receive.buffer.bytes：设置Socket接收消息缓冲区的大小。默认值64KB。-1则使用操作系统默认值。")]),s._v(" "),a("li",[s._v("send.buffer.bytes：设置方式陪Socket发送消息缓冲区的大小，默认值128KB。-1则使用操作系统默认值。")]),s._v(" "),a("li",[s._v("request.timeout.ms：设置consumer等待请求响应的最长时间。默认值30000ms。")]),s._v(" "),a("li",[s._v("metadata.max.age.ms：元数据过期时间，默认值5分钟。若在该时间段内未更新则被强制更新。")]),s._v(" "),a("li",[s._v("reconnect.backoff.ms：配置尝试重新连接指定主机之前的等待时间(退避时间)，默认值50ms。避免频繁连接主机。适用于消费者向broker发送的所有请求。")]),s._v(" "),a("li",[s._v("retry.backoff.ms：配置尝试重新发送失败的请求到指定主题分区之前的等待时间。避免在某些故障情况下频繁地重复发送。")]),s._v(" "),a("li",[s._v('isolation.level：配置消费者事务隔离级别。默认值"read_uncommitted"。\n'),a("ul",[a("li",[s._v("read_uncommitted：poll将返回所有消息，甚至是已中止的事务性消息，可以读到HW。")]),s._v(" "),a("li",[s._v("read_committed：poll将仅返回已提交的事务性消息。最多只能返回LSO(稳定偏移量，已经提交的偏移量)的消息，比未提交的偏移量小1。")])])]),s._v(" "),a("li",[s._v("session.timeout.ms：默认值10000ms。组管理协议中用来检测消费者是否失效的超时时间。")]),s._v(" "),a("li",[s._v("heartbeat.interval.ms：默认值3000ms。当时用分组管理功能时，心跳到消费者协调器之间的预计时间。该值必须比session.timeout.ms小，通常不高于1/3。已控制正常再平衡的预期时间。")]),s._v(" "),a("li",[s._v("max.poll.interval.ms：默认值300000ms。当通过消费组管理消费者时，该配置指定拉取消息线程最长空闲时间，若超过这个时间间隔还没有发起poll操作，则消费组认为消费者已经离开，将进行再平衡操作。")]),s._v(" "),a("li",[s._v("partition.aggignment.strategy：分区分配策略。")]),s._v(" "),a("li",[s._v("interceptor.class：拦截器。")])]),s._v(" "),a("p",[s._v("9 10a 11b 12c 13d 14e 15f")])])}),[],!1,null,null,null);a.default=r.exports}}]);